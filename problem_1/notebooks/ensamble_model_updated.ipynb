{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils.validation import check_X_y\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./clean_data_dropped.csv\")\n",
    "targets = data.pop(list(data.columns)[-1])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, targets, test_size=0.3, random_state=121, stratify=targets\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_test, y_test, test_size=0.67, random_state=121, stratify=y_test\n",
    ")\n",
    "data = {}\n",
    "data[\"train\"] = [X_train, y_train]\n",
    "data[\"val\"] = [X_val, y_val]\n",
    "data[\"test\"] = [X_test, y_test]\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "class_weights = {}\n",
    "total_samples = np.sum(counts)\n",
    "for cls in class_counts:\n",
    "    class_weights[cls] = total_samples / (len(class_counts) * class_counts[cls])\n",
    "sample_weights = np.array([class_weights[cls] for cls in y_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "lgbm = LGBMClassifier()\n",
    "svc = SVC(probability=True)\n",
    "xgb_calibrated = CalibratedClassifierCV(xgb, method=\"sigmoid\", cv=5)\n",
    "lgbm_calibrated = CalibratedClassifierCV(lgbm, method=\"sigmoid\", cv=5)\n",
    "svc_calibrated = CalibratedClassifierCV(svc, method=\"sigmoid\", cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, estimators, voting=\"hard\"):\n",
    "        self.estimators = estimators\n",
    "        self.voting = voting\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        for estimator in self.estimators:\n",
    "            estimator.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Use majority vote for hard voting\n",
    "        if self.voting == \"hard\":\n",
    "            votes = np.asarray([estimator.predict(X) for estimator in self.estimators])\n",
    "            return np.median(votes, axis=0)\n",
    "\n",
    "        # Use weighted average for soft voting\n",
    "        elif self.voting == \"soft\":\n",
    "            probs = np.asarray(\n",
    "                [estimator.predict_proba(X) for estimator in self.estimators]\n",
    "            )\n",
    "            avg_probs = np.average(probs, axis=0)\n",
    "            return np.argmax(avg_probs, axis=1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probs = np.asarray(\n",
    "            [estimator.predict_proba(X) for estimator in self.estimators]\n",
    "        )\n",
    "        avg_probs = np.average(probs, axis=0)\n",
    "        return avg_probs\n",
    "\n",
    "    def optimize_threshold(self, X, y_true):\n",
    "        y_true = np.array(y_true)\n",
    "        y_prob = self.predict_proba(X)\n",
    "        fprs, tprs, thresholds = roc_curve(y_true, y_prob[:, 1])\n",
    "        opt_idx = np.argmax(tprs - fprs)\n",
    "        self.threshold = thresholds[opt_idx]\n",
    "\n",
    "    def predict_with_threshold(self, X):\n",
    "        if not hasattr(self, \"threshold\"):\n",
    "            raise AttributeError(\n",
    "                \"You need to call optimize_threshold before using predict_with_threshold\"\n",
    "            )\n",
    "        probs = self.predict_proba(X)\n",
    "        y_pred = np.where(probs[:, 1] > self.threshold, 1, 0)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "def report_metrics(y_true, y_pred_prob, threshold=0.5):\n",
    "    y_pred = (y_pred_prob > threshold).astype(int)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc_roc = roc_auc_score(y_true, y_pred_prob)\n",
    "    auc_pr = average_precision_score(y_true, y_pred_prob)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"auc_roc\": auc_roc,\n",
    "        \"auc_pr\": auc_pr,\n",
    "        \"threshold\": threshold,\n",
    "    }\n",
    "\n",
    "    return metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting_clf = VotingClassifier(\n",
    "#     estimators=[xgb_calibrated, lgbm_calibrated, svc_calibrated],\n",
    "#     voting=\"hard\",\n",
    "# )\n",
    "# voting_clf.fit(data[\"train\"][0].values, data[\"train\"][1].values)\n",
    "# voting_clf.optimize_threshold(data[\"train\"][0].values, data[\"train\"][1].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = voting_clf.predict_with_threshold(X=data[\"train\"][0].values)\n",
    "# y_pred_probs = voting_clf.predict_proba(X=data[\"train\"][0].values)\n",
    "# y_pred_probs = torch.softmax(\n",
    "#     torch.Tensor(voting_clf.predict_proba(X=data[\"train\"][0].values)), dim=1\n",
    "# ).numpy()[:, 1]\n",
    "\n",
    "# report_metrics(\n",
    "#     y_true=data[\"train\"][1].values,\n",
    "#     y_pred_prob=y_pred_probs,\n",
    "#     threshold=voting_clf.threshold,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = voting_clf.predict_with_threshold(X=data[\"val\"][0].values)\n",
    "# y_pred_probs = voting_clf.predict_proba(X=data[\"val\"][0].values)\n",
    "# y_pred_probs = torch.softmax(\n",
    "#     torch.Tensor(voting_clf.predict_proba(X=data[\"val\"][0].values)), dim=1\n",
    "# ).numpy()[:, 1]\n",
    "\n",
    "# report_metrics(\n",
    "#     y_true=data[\"val\"][1].values,\n",
    "#     y_pred_prob=y_pred_probs,\n",
    "#     threshold=voting_clf.threshold,\n",
    "# )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuralnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(DeepNetwork, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        for i, hidden_size in enumerate(hidden_sizes):\n",
    "            if i == 0:\n",
    "                self.fc_layers.append(nn.Linear(input_size, hidden_size))\n",
    "            else:\n",
    "                self.fc_layers.append(nn.Linear(hidden_sizes[i - 1], hidden_size))\n",
    "            self.fc_layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            self.fc_layers.append(nn.Dropout(0.5))\n",
    "            self.fc_layers.append(nn.ReLU())\n",
    "\n",
    "        self.fc_layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.fc_layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                x = x.type_as(layer.weight)\n",
    "            x = layer(x)\n",
    "        return nn.functional.softmax(x)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = torch.tensor(X, dtype=torch.float)\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(X)\n",
    "            # probs = self.softmax(logits)\n",
    "        return logits.numpy()\n",
    "\n",
    "    def optimize_threshold(self, X, y_true):\n",
    "        y_true = np.array(y_true)\n",
    "        y_prob = self.predict_proba(X)[:, 1]\n",
    "        fprs, tprs, thresholds = roc_curve(y_true, y_prob)\n",
    "        opt_idx = np.argmax(tprs - fprs)\n",
    "        self.threshold = thresholds[opt_idx]\n",
    "\n",
    "    def predict_with_threshold(self, X):\n",
    "        if not hasattr(self, \"threshold\"):\n",
    "            raise AttributeError(\n",
    "                \"You need to call optimize_threshold before using predict_with_threshold\"\n",
    "            )\n",
    "        probs = self.predict_proba(X)[:, 1]\n",
    "        y_pred = np.where(probs > self.threshold, 1, 0)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "input_size = data[\"train\"][0].shape[\n",
    "    1\n",
    "]  # replace this with the actual input size of your data\n",
    "hidden_sizes = sorted([2 ** random.randint(3, 10) for k in range(10)])[::-1]\n",
    "output_size = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = DeepNetwork(\n",
    "    input_size=data[\"train\"][0].shape[1], hidden_sizes=hidden_sizes, output_size=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels, label_counts = np.unique(y_train, return_counts=True)\n",
    "class_weights = 1.0 / label_counts\n",
    "class_weights /= np.sum(class_weights)\n",
    "batch_size = 64\n",
    "\n",
    "train_set = TensorDataset(\n",
    "    torch.from_numpy(data[\"train\"][0].values), torch.from_numpy(data[\"train\"][1].values)\n",
    ")\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=class_weights, num_samples=len(train_set), replacement=True\n",
    ")\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "val_set = TensorDataset(\n",
    "    torch.from_numpy(data[\"val\"][0].values), torch.from_numpy(data[\"val\"][1].values)\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader))[-1]\n",
    "\n",
    "# tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "#         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "#         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DeepNetwork(input_size, hidden_sizes, output_size).to(device)\n",
    "criterion = nn.BCELoss(weight=torch.tensor(class_weights).to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    for batch in train_loader:\n",
    "        X, targets = batch[0].to(device), batch[1].to(device)\n",
    "        outputs = model(X)\n",
    "        print(targets)\n",
    "        loss = criterion(outputs, targets.unsqueeze(1).float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * X.size(0)\n",
    "        train_correct += torch.sum(torch.argmax(outputs, dim=1) == targets)\n",
    "\n",
    "    train_loss /= len(train_loader.sampler)\n",
    "    train_acc = train_correct.double() / len(train_loader.sampler)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            X, targets = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            val_loss += loss.item() * X.size(0)\n",
    "            val_correct += torch.sum(torch.argmax(outputs, dim=1) == targets)\n",
    "\n",
    "    val_loss /= len(val_loader.sampler)\n",
    "    val_acc = val_correct.double() / len(val_loader.sampler)\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
